# Stack PTX

## Overview

Stack PTX is a single-file, header-only C library that takes a sequence of instructions and outputs PTX that reflects those instructions being run on a stack machine. The language was heavily inspired by Professor Lee Spectorâ€™s [Push](https://faculty.hampshire.edu/lspector/push.html) language and systems.

The library has no dependencies other than the standard C library and is C99 compliant. Similar to the [stb single-header libraries](https://github.com/nothings/stb), `stack_ptx.h` serves as both header and implementation. As such, `STACK_PTX_IMPLEMENTATION` should be defined before including `stack_ptx.h` in exactly one compilation unit, e.g.:
```c
#define STACK_PTX_IMPLEMENTATION
#include <stack_ptx.h>
```
Defining `STACK_PTX_DEBUG` turns every error returned in the library into an `assert` at the call site for easier debugging, e.g.:
```c
#define STACK_PTX_DEBUG
#define STACK_PTX_IMPLEMENTATION
#include <stack_ptx.h>
```

Each function in this library returns an error code that should be checked (just like the CUDA APIs). A `stackPtxCheck` macro is provided for convenience.

A separate header file, [`generated_headers/stack_ptx_generated_descriptions.h`](generated_headers/stack_ptx_generated_descriptions.h), contains descriptions for PTX assembly instructions that are compatible with Stack PTX. This file is generated by the Python script [`tools/stack_ptx_generate_infos.py`](tools/stack_ptx_generate_infos.py) from the json file [`type_descriptions/stack_ptx_descriptions.json`](type_descriptions/stack_ptx_descriptions.json).
You can easily edit the `JSON` file to add, remove, or customize the PTX instructions that Stack PTX has access to. Regenerate a new `stack_ptx_generated_descriptions.h` with:
```bash
python ~/mm-ptx/tools/stack_ptx_generate_infos.py --input ~/mm-ptx/type_descriptions/stack_ptx_descriptions.json --output ~/mm-ptx/generated_headers/stack_ptx_default_generated_types.h --lang c
```

## Motivation

The motivation for this API is to allow easy creation of valid PTX code. For example, in PTX you might write:
```c
mul.ftz.f32 %f0, 1.0, 2.0;
add.ftz.f32 %f1, %f0, 0.2;
```
With Stack PTX youâ€™d express this as:
```c
[ stack_ptx_encode_constant_f32(1.0),
  stack_ptx_encode_constant_f32(2.0),
  stack_ptx_encode_ptx_instruction_mul_ftz_f32,
  stack_ptx_encode_constant_f32(0.2),
  stack_ptx_encode_ptx_instruction_add_ftz_f32,
  stack_ptx_encode_return
]
```
In the above example:
* `stack_ptx_encode_constant_f32(1.0)` pushes `1.0` onto the stack.
* `stack_ptx_encode_constant_f32(2.0)` pushes `2.0` onto the stack.
* `stack_ptx_encode_ptx_instruction_mul_ftz_f32` pops the top two float values from the stack and multiplies them. If the stack doesnâ€™t contain two values, the operation is skipped. Since `1.0` and `2.0` are on the stack, the operation is successful and an AST value representing the result is pushed onto the stack.
* `stack_ptx_encode_constant_f32(0.2)` pushes `0.2` onto the stack.
* `stack_ptx_encode_ptx_instruction_add_ftz_f32` pops the top two float values from the stack and adds them. One operand is `0.2`; the other is the AST value representing the earlier multiply.

Because this is expressed as stack operations, any operation can be deleted, inserted, or swapped at any position and youâ€™ll still have a valid series of PTX instructions. The Stack PTX compiler implements dead-code elimination on the AST, so operations that arenâ€™t relevant to the requested stack values donâ€™t appear in the generated PTX.

When the above code runsâ€”assuming there is one request for an `F32` stack value for a register named `output_register`â€”the emitted PTX looks like:
```
{
  .reg .f32 %_a<2>;
  mul.ftz.f32 %_a0, 0f40000000, 0f3F800000;
  add.ftz.f32 %_a1, 0f3E4CCCCD, %_a0;
  mov.f32 %output_register, %_a1;
}
```

Additionally, PTX generation in this system is extremely fast. Given ~100 instructions, the system can output valid PTX in single-digit **microseconds**.

Stack PTX code **can** be written by humans, but it is much better suited to programmatic generation.

## Examples

- **Stack PTX only**
  - ðŸ“š Overview: [examples/stack_ptx/README.md](examples/stack_ptx/README.md)
  - âœ… Quickstart (simplest): [examples/stack_ptx/00_simple/main.c](examples/stack_ptx/00_simple/main.c)

- **PTX Inject**
  - ðŸ“– Readme / concepts: [PTX_INJECT.md](PTX_INJECT.md)

- **Combined (Stack PTX + PTX Inject)**
  - ðŸ”— Integrated examples: [examples/stack_ptx_inject/README.md](examples/stack_ptx_inject/README.md)

- **Python Bindings for Stack PTX + PTX Inject + Examples**
  - https://github.com/MetaMachines/mm-ptx-py

- **PyTorch Customizable Hyperparameter Semirings**
  - https://github.com/MetaMachines/mm-kermac-py

## Tutorial / Explanation

### Stacks
As the name implies, Stack PTX uses stack data structures to store intermediate data while executing instructions and to record updates to its AST while compiling. Instructions can push data onto stacks, pop data from stacks, or do both.

### The Interface
Stack PTX exposes three functions:
* **`stack_ptx_result_to_string`**: Returns the string representation of a `StackPtxResult`.
* **`stack_ptx_compile_workspace_size`**: Returns the amount of memory `stack_ptx_compile` will need to compile its programs. This factors in settings such as the number of stacks, the depth of each stack, the maximum number of AST elements, etc.
* **`stack_ptx_compile`**: The workhorse of Stack PTX. The most important parameters are `instructions`, `registers`, and `requests`.

## Instructions
Stack PTX primarily relies on the `StackPtxInstruction` struct to describe what to do. This struct is fixed-sizeâ€”**8 bytes** (64 bits). Most data related to compilation for the instruction is stored in these 8 bytes, except the string representations that end up in PTX code (such as `"add.ftz.f32"`, `"mul.ftz.f32"`, etc.).

Instructions are fixed-size to make it easy to shuffle instruction around, assemble them on the fly, or delete random elements from the instruction array without breaking anything. You should be able to throw any set of instructions into the instruction array and expect valid, runnable PTX assembly as output.

### Return
Return is the simplest instruction. Itâ€™s a sentinel value signaling the end of execution for an array of instructions, avoiding the need to pass a length to `stack_ptx_compile`. Encode it with:
```
stack_ptx_encode_return
```
Instruction lists in [mm-ptx-py](https://github.com/MetaMachines/mm-ptx-py) donâ€™t need this instructionâ€”itâ€™s automatically appended just before compiling.

### Constants
The simplest instruction that does work is the constant instruction, which pushes a constant value onto the relevant stack. The declared constant is limited to 32 bits because it is stored inside the instruction itself. For example, in `generated_headers/stack_ptx_default_generated_types.h`:
```c
stack_ptx_encode_constant_f32(1.0f)
stack_ptx_encode_constant_u32(10)
```
These push `1.0f` to the `F32` stack and `10` to the `U32` stack, respectively.

### Meta Instructions
Meta instructions are inspired by [Push](https://faculty.hampshire.edu/lspector/push.html) (Prof. [Lee Spector](https://faculty.hampshire.edu/lspector/)). These operate on the stacks during construction of the AST, before the AST is compiled to PTX. If not enough values are present on the relevant stackâ€”or, for indexed instructions, if the `meta_stack` is emptyâ€”the meta instruction is ignored. If an indexed meta instruction pops a value off the `meta_stack` and it refers to a depth deeper than available, the instruction is also ignored.

A runnable example for meta instructions is at [examples/stack_ptx/03_meta_instructions](examples/stack_ptx/03_meta_instructions).

#### Meta `constant`
Pushes an integer onto the special `meta_stack` to be used by other meta instructions that require an integer input.
```c
stack_ptx_encode_meta_constant(2)
```

#### Meta `dup`
Duplicates the top value of the relevant stack.
```c
stack_ptx_encode_meta_dup(STACK_PTX_STACK_TYPE_F32)
```
The above duplicates the top value on the `F32` stack, so there are now two copies at the top.

#### Meta `yank_dup`
Like `dup`, but pops an integer from the `meta_stack` as a depth parameter. It reaches that depth into the relevant stack and duplicates that value to the top, leaving the original in place.
```c
stack_ptx_encode_meta_yank_dup(STACK_PTX_STACK_TYPE_F32)
```

#### Meta `swap`
Swaps the top two values of the relevant stack.
```c
stack_ptx_encode_meta_swap(STACK_PTX_STACK_TYPE_U32)
```

#### Meta `swap_with`
Like `swap`, but pops an integer from the `meta_stack` as a depth parameter. It reaches that depth in the relevant stack and swaps that value with the current top.
```c
stack_ptx_encode_meta_swap_with(STACK_PTX_STACK_TYPE_U32)
```

#### Meta `replace`
Similar to `swap_with`: it pops an integer from the `meta_stack` as a depth parameter. Instead of swapping with the top, it replaces the element at that depth with the current top value.
```c
stack_ptx_encode_meta_replace(STACK_PTX_STACK_TYPE_U32)
```

#### Meta `drop`
Reads an integer value from the `meta_stack` and drops that many elements from the relevant stack.
```c
stack_ptx_encode_meta_drop(STACK_PTX_STACK_TYPE_U32)
```

#### Meta `rotate`
Moves the top of the stack two positions down (`abc` becomes `bca`).
```c
stack_ptx_encode_meta_rotate(STACK_PTX_STACK_TYPE_U32)
```

#### Meta `reverse`
Reverses the order of a stack (`abcd` becomes `dcba`).
```c
stack_ptx_encode_meta_reverse(STACK_PTX_STACK_TYPE_U32)
```

### Inputs
Inputs push externally declared PTX registers onto the relevant stack. They require an index to identify them. This index is used to access their string register name passed to `stack_ptx_compile` via the `const StackPtxRegister* registers` parameter. `StackPtxRegister` contains the registerâ€™s string name and its stack type. The index used to encode the input `StackPtxInstruction` is used to access that inputâ€™s register data. For example:
```c
stack_ptx_encode_input(0),
stack_ptx_encode_input(2)
```
When the above instructions run, they grab their register information from elements `0` and `2` of the `StackPtxRegister registers` array. Itâ€™s common to use **enums** to maintain consistent naming for these indices. See [`examples/stack_ptx/00_simple/main.c`](examples/stack_ptx/00_simple/main.c).

### PTX Instructions
PTX instruction encodings specify the actual PTX ops that will appear in the output from `stack_ptx_compile`. They are still **8 bytes** long; their payload contains all the information for which stacks to pop from and which stacks to push to. See [`type_descriptions/stack_ptx_descriptions.json`](type_descriptions/stack_ptx_descriptions.json). Each instruction can consume up to 4 inputs and produce up to 2 outputs, per the [PTX ISA](https://docs.nvidia.com/cuda/parallel-thread-execution/) spec. Encode them like:
```c
stack_ptx_encode_ptx_instruction_add_u32,
stack_ptx_encode_ptx_instruction_mul_ftz_f32
```
From the descriptions JSON file, `stack_ptx_encode_ptx_instruction_add_u32` reads two values from the `U32` stack and pushes one value back to the `U32` stack. `stack_ptx_encode_ptx_instruction_mul_ftz_f32` reads two values from the `F32` stack and pushes one value back to the `F32` stack.

Instructions can be more complex because argument descriptors are *arg types*, not just stack types. For example, `V4_F32` means the instruction should read 4 values from the `F32` stack when used as an input, and push 4 values to the `F32` stack when used as a return. These correspond to PTX vector operands like `{%a0, %a1, %a2, %a3}`. See [`examples/stack_ptx/06_mma/main.c`](examples/stack_ptx/06_mma/main.c) for a tensor core instruction example and [`examples/stack_ptx_inject/03_mma_sync`](examples/stack_ptx_inject/03_mma_sync) for a combined example.

### Special Registers
Special-register instructions are similar to PTX instructions in that they use arg types to describe their behavior. They exist to encode PTX special-register strings into PTX. In [`type_descriptions/stack_ptx_descriptions.json`](type_descriptions/stack_ptx_descriptions.json), see the `special_registers` section. For example, `tid.x` pushes its value to the `U32` stack. `tid` uses the arg type `V4_U32` and pushes 4 values to the `U32` stack. You will then find `tid.x`, `tid.y`, `tid.z`, and `tid.w` in the output PTX, representing the equivalents of `threadIdx.x`, `threadIdx.y`, etc. in CUDA. See [`examples/stack_ptx/04_special_registers/main.c`](examples/stack_ptx/04_special_registers/main.c).
```c
stack_ptx_encode_special_register_tid_x,
stack_ptx_encode_special_register_tid
```

### Store/Load
Store and load instructions let you stash values from a stack and recall them later. This can greatly help human programmers express intended behavior. When `store` runs, it pops one value from the requested stack and writes it to a load/store array at the provided index. Running `load` with the same index pushes that value back onto the stack. You can call `load` multiple times to reuse the same stored value. If `load` is called for an index that was never stored to, the instruction is ignored.
```c
stack_ptx_encode_store(STACK_PTX_STACK_TYPE_F32, 0)
stack_ptx_encode_load(0)
```
For an example, see [`examples/stack_ptx/07_store_load`](examples/stack_ptx/07_store_load).

## Routines
Routines are passed into `stack_ptx_compile` as a parameter. Each routine in the `routines` array is another array of instructions, similar to the main `instructions` array. A routine can be invoked by an instruction in the main array, and routines can call other routines. The struct `StackPtxCompilerInfo` contains a parameter called `max_frame_depth` that sets the maximum call depth for routines before returning. Like the main instruction array, each routine must be terminated with `stack_ptx_encode_return`.
```c
stack_ptx_encode_routine(0)
```
Examples:
* [`examples/stack_ptx/01_routines`](examples/stack_ptx/01_routines)
* [`examples/stack_ptx/02_routine_libraries`](examples/stack_ptx/02_routine_libraries)

## Requests
Requests are passed into `stack_ptx_compile` as a parameter. Whereas `input` instructions allow external registers to appear as arguments in Stack PTXâ€“generated PTX, requests allow external registers to be set **by** Stack PTXâ€“generated instructions.

Each request represents an index in the `const StackPtxRegister* registers` array. For each entry in the `requests` array, the relevant stack information is looked up from `registers`. The stack value associated with that request is popped, and a `mov` instruction is generated, setting the internal Stack PTX register to the string value of the external register.

# Custom Types
Stack PTX is designed to be unaware of specific stack types, arg types, and PTX instruction sets. It operates from tables provided to it to generate PTX assembly. This allows you to customize your setup as you wish.

The default types used by the `examples` are in [`type_descriptions/stack_ptx_descriptions.json`](type_descriptions/stack_ptx_descriptions.json). A very simple description is in [`type_descriptions/stack_ptx_simple.json`](type_descriptions/stack_ptx_simple.json).

To regenerate [`generated_headers/stack_ptx_default_generated_types.h`](generated_headers/stack_ptx_default_generated_types.h), use the Python script:
```bash
python ~/mm-ptx/tools/stack_ptx_generate_infos.py --input ~/mm-ptx/type_descriptions/stack_ptx_descriptions.json --output ~/mm-ptx/generated_headers/stack_ptx_default_generated_types.h --lang c
```
This script declares all the encoding macros for Stack PTX using the given types.

# C++
This project is written in C but is compliant with C++. To use C++, generate the C++ version of the generated headers instead of the C version. The C version uses macros and designated initializers to allow declarations like `static const StackPtxInstruction[] = { ... };`. To generate the C++ headers, specify `--lang cpp` instead of `--lang c`:
```bash
python ~/mm-ptx/tools/stack_ptx_generate_infos.py --input ~/mm-ptx/type_descriptions/stack_ptx_descriptions.json --output ~/mm-ptx/generated_headers/stack_ptx_default_generated_types.hpp --lang cpp
```
This generates the C++ equivalent of the C generated header. It uses `constexpr` to allow `static const StackPtxInstruction[] = { ... };` and includes convenient namespaces and enums.

## License
This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
